---
title: "preliminary_analysis_Odonata"
author: "Diana Bowler"
date: "24 januar 2018"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

```

#Analysis of the Odonata data from Saarland

First step: read in the raw data file from the sMon data portal.
Sheet 5 of the workbook contains the raw data of occurrences.
Each row in the data frame is a species observation.

```{r warning=FALSE}

library(gdata)
df <- read.xls("raw-data/Odonata_Saarland_Trockur.xls",sheet=5)

```

#Data frame formatting

Step one: format the date and extract month, dat and year information.

```{r}

library(lubridate)
df$Date <- as.Date(df$Date,file="%Y-%m-%d")
df$month <- month(df$Date)
df$day <- yday(df$Date)
df$year <- year(df$Date)

```

Step two: remove those with missing date entries

```{r}

df <- subset(df,!is.na(month))

```


#Data filtering

Filter one: focus on the months that were most sampled. The results suggest this is between April and September.

```{r}

table(df$month)

df <- subset(df, month %in% c(4:9))

```

Filter two: begin the time series from the first year with reasonable amount of data (i.e., number of records). 1981 seems like a good place to start. Also, we cut off 2017 incase the database is not up-to-date yet.

```{r}

table(df$Year)
df <- subset(df, Year>1980)
df <- subset(df, Year<2017)

```

#Data availability/Sampling effort checking

We can look at effort by: total number of records and average number of species seen per sampling day ("list length")

```{r}

library(sparta)

dataDiagnostics(taxa= as.character(df$Species), 
                site= as.character(df$MTB_Q), 
                time_period = df$Date)

```


#Study Phenology

We need to check the pattern of activity over the year to see how we should model phenology.

```{r fig.height = 6, fig.width = 8}

#using abundance data corrected by effort

#first get number of species seen per sampling day as a measure of sampling effort:
library(plyr)
samplingEffort <- ddply(df, .(MTB_Q,Date), summarise, LL=length(Anzahl_min))
#add it to the data frame
df$samplingEffort <- samplingEffort$LL[match(interaction(df$Date,df$MTB_Q),
                                             interaction(samplingEffort$Date,samplingEffort$MTB_Q))]
#plots counts/sampling effort over time
df$yday <- yday(df$Date)
library(ggplot2)
ggplot(subset(df,Species %in% names(table(df$Species))[table(df$Species)>50]))+
      geom_point(aes(x=yday, y=Anzahl_min/samplingEffort,colour=Year),alpha=0.5)+
      facet_wrap(~Species)+
      scale_y_log10()+
      theme_bw()+
      scale_colour_gradient(low="steelblue",high="salmon")+
      ylab("Count/Effort")+
      xlab("day of year")+
      theme(strip.text = element_text(size=rel(0.6)))

```

#Model fitting
Use the sparta package (https://github.com/BiologicalRecordsCentre/sparta) to fit an occupancy detection model.
(Note: the data file does also include information on counts, but for the moment we only use information on species presence)

```{r cache=T}
library(sparta)

# settings
sparta_options <- c('ranwalk', # prior on occupancy is set by last year's posterior
                    'jul_date', # use the Julian date as a covariate on the detection probability
                    'catlistlength', # categorises the visits into three sets of 'qualities'
                    'halfcauchy') # prior on the precisions

#odonata_occmod <- occDetModel(taxa= as.character(df$Species), 
#                            site= as.character(df$MTB_Q), 
#                            time_period = df$Date,
#                            modeltype = sparta_options,
#                            n_iterations = 10000)


```

#Plotting the predictions

Plot the predicting occupancy rates (% of sites occupied per year) for each species.

Step one: Get the list of model files that sparta spat out from the previous code chunk. These are contained within the 'model-outputs' folder.

```{r}
source("R/sparta_wrapper_functions.R")

models<-getSpartaModels("model-outputs")

```

Step two: Pull out the annual predictions of model occupancy per species

```{r}
#in sparta wrapper functions

myAnnualPredictions <- annualPredictions(models)
head(myAnnualPredictions)

```

#Plotting the time series

Plot the predicted time series for species with more than 50 records.
Pink means that this model did not converge (i.e., Rhat was not less than 1.1).
We can try running the model for more iterations to see if it will converge.

```{r fig.height = 8, fig.width = 8}

#in sparta wrapper functions
plotPredictions(myAnnualPredictions)

```

#Quantify the linear long-term trends of each species

```{r kable}

#in sparta wrapper functions
library(knitr)
kable(calculateTrends(models),digits=3)

```


#Examine the spatial pattern 

Pull out the model predictions for each site in a given year.

```{r}

setwd("model-outputs")
load("Aeshna affinis.rdata")
library(jagsUI)

updated_model <- update(out$model, parameters.to.save = "z", n.iter = 5000)

#will need to tweak the update function from jagsUI
#https://github.com/kenkellner/jagsUI/blob/master/R/update.R

#recompile(jagsfit)
#jagsfit.upd <- update(jagsfit, n.iter=100
                      
```

#Further model checking

Pull out the model chains to check convergence.
(i.e. plot iteration number vs sampled parameter).

```{r}

#convert the chains into a dataframe

#from model list create a directory and save a traceplot for each species

plotModels<-function(model.list,param="psi.fs"){

#create a directory to put the traceplots
newdir <- file.path("model-outputs", "traceplots")
dir.create(newdir)
setwd(newdir)

#for each species, do the following
  
library(reshape2)
df<-melt(out$BUGSoutput$sims.array)

ggsave(paste(x$SPP_Name,"png",sep="."))
ggplot(subset(df,grepl(param,df$Var3)))+
  geom_path(aes(x=Var1,y=value,colour=factor(Var2)))+
  facet_wrap(~Var3,scales="free")+
  theme_bw()+
  theme(legend.position="none")
dev.off()
}

```

