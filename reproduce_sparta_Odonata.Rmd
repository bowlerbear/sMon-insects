---
title: "preliminary_analysis_Odonata"
author: "Diana Bowler"
date: "24 januar 2018"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

```

#Analysis of the Odonata data from Saarland

First step: read in the raw data file from the sMon data portal.
Sheet 5 of the workbook contains the raw data of occurrences.
Each row in the data frame is a species observation.

```{r warning=FALSE}

library(gdata)
df <- read.xls("raw-data/Odonata_Saarland_Trockur.xls",sheet=5)

```

#Data frame formatting

Step one: format the date and extract month, dat and year information.

```{r}

library(lubridate)
df$Date <- as.Date(df$Date,file="%Y-%m-%d")
df$month <- month(df$Date)
df$day <- yday(df$Date)
df$year <- year(df$Date)

```

Step two: remove those with missing date entries

```{r}

df <- subset(df,!is.na(month))

```


#Data filtering

Filter one: focus on the months that were most sampled. The results suggest this is between April and September.

```{r}

table(df$month)

df <- subset(df, month %in% c(4:9))

```

Filter two: begin the time series from the first year with reasonable amount of data (i.e., number of records). 1981 seems like a good place to start. Also, we cut off 2017 incase the database is not up-to-date yet.

```{r}

table(df$Year)
df <- subset(df, Year>1980)
df <- subset(df, Year<2017)

```

#Data availability/Sampling effort checking

We can look at effort by: total number of records and average number of species seen per sampling day ("list length")

```{r}

library(sparta)

dataDiagnostics(taxa= as.character(df$Species), 
                site= as.character(df$MTB_Q), 
                time_period = df$Date)

```

Summary info per species

```{r}

library(plyr)
ddply(df,.(Species),summarise,nuRecs=length(unique(Date)),nuYears=length(unique(Year)),nuSites=length(unique(MTB_Q)))

```

Organise data using the sparta function

```{r}

tempDF <- formatOccData(taxa= as.character(df$Species), 
                site= as.character(df$MTB_Q), 
                time_period = df$Date,
                includeJDay = TRUE)

#get occurence matrix
occurrenceDF <- tempDF$spp_vis
occurrenceInfo <- data.frame(visit = occurrenceDF$visit)
#pull out other info
occurrenceInfo$Date <- sapply(occurrenceInfo$visit,function(x)substr(x,6,15)) 
occurrenceInfo$Date <- as.Date(occurrenceInfo$Date)
occurrenceInfo$Year <- year(occurrenceInfo$Date) 
occurrenceInfo$Site <- sapply(occurrenceInfo$visit,function(x)substr(x,1,5)) 
length(unique(occurrenceInfo$Site))#94 sites

#get list length for each visit
listlengthDF <- tempDF$occDetdata
length(unique(occurrenceInfo$Site))
length(unique(listlengthDF$site))#94 sites
listlengthDF$siteIndex<-as.numeric(factor(listlengthDF$site))
listlengthDF$yearIndex<-as.numeric(factor(listlengthDF$year))

```

Compile data for bugs (for a select species  - here )

```{r}

mySpecies<-"Aeshna cyanea"

bugs.data <- list(nsite = length(unique(listlengthDF$site)),
                  nyear = length(unique(listlengthDF$year)),
                  nvisit = nrow(listlengthDF),
                  site = listlengthDF$siteIndex,
                  year = listlengthDF$yearIndex,
                  Jul_date = listlengthDF$Jul_date - median(listlengthDF$Jul_date),
                  L = listlengthDF$L - median(listlengthDF$L),
                  y = ifelse(occurrenceDF[,mySpecies] == FALSE,0,1))
                  
```

Run model

```{r}
source('R/BUGS_misc_functions.R')

#specify parameters to monitor
params <- c("psi.fs","beta1","beta1","dtype.p","mu.lp")

#need to specify initial values
occurrenceInfo$Species <- bugs.data$y
library(reshape2)
zst <- acast(occurrenceInfo, Site~Year, value.var="Species",fun=max)
zst [is.infinite(zst)] <- 0
inits <- function(){list(z = zst)}

#run model
out1 <- jags(bugs.data, inits=inits, params, "R/BUGS_sparta.txt", n.thin=nt,
               n.chains=3, n.burnin=500,n.iter=2000,parallel=T)
print(out1,2)

```


Model checking

```{r}

save(out1,file=paste0("model-outputs/out1_",mySpecies,".RData"))

#other graphs
#see http://xavier-fim.net/packages/ggmcmc/
library(ggmcmc)
bayes.mod.fit.gg <- ggs(out1$samples,family="psi.fs")
bayes.mod.fit.gg$ParamNu <- as.numeric(sub(".*\\[([^][]+)].*", "\\1", bayes.mod.fit.gg$Parameter))

#save the attribites becasue they are lost in the subsetting step below, dont understand why..
my_attributes<-attributes(bayes.mod.fit.gg)
bayes.mod.fit.gg <- subset(bayes.mod.fit.gg,ParamNu%%5==0)#plot every 5
attributes(bayes.mod.fit.gg)<-c(attributes(bayes.mod.fit.gg),my_attributes[3:8])

#plots
ggs_histogram(bayes.mod.fit.gg)
ggs_density(bayes.mod.fit.gg)
ggs_traceplot(bayes.mod.fit.gg)

```

Extract z to look at spatial patterns

```{r}
out2<-update(out1,parameters.to.save="z",n.iter=1000)

#pull out site and year
zSummary<-data.frame(out2$summary[grepl("z",row.names(out2$summary)),])
zSummary$ParamNu <- as.character(sub(".*\\[([^][]+)].*", "\\1", row.names(zSummary)))
zSummary$Site<-sapply(zSummary$ParamNu,function(x)strsplit(x,",")[[1]][1])
zSummary$Year<-sapply(zSummary$ParamNu,function(x)strsplit(x,",")[[1]][2])

#create a site Info dataset
allData<-expand.grid(MTB_Q=unique(df$MTB_Q),Year=unique(df$Year))
allData$lon<-df$lon[match(allData$MTB_Q,df$MTB_Q)]
allData$lat<-df$lat[match(allData$MTB_Q,df$MTB_Q)]
allData$siteIndex<-listlengthDF$siteIndex[match(allData$MTB_Q,listlengthDF$site)]
allData$yearIndex<-listlengthDF$yearIndex[match(allData$Year,listlengthDF$year)]
allData$meanProp<-zSummary$mean[match(interaction(allData$siteIndex,allData$yearIndex),
                                           interaction(zSummary$Site,zSummary$Year))]
```

Plot spatial pattern in occupancy

```{r}

ggplot(subset(allData,Year%in% c(min(Year),max(Year))),
       aes(x=lon,y=lat))+
  geom_point(aes(colour=meanProp),size=rel(12),shape=15)+
  scale_colour_gradient(low="steelblue",high="red")+
  theme_bw()+
  facet_wrap(~Year)

```